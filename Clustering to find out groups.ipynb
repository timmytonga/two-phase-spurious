{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7be14ce",
   "metadata": {},
   "source": [
    "# Clustering for group info\n",
    "\n",
    "## TODO\n",
    "- First load the trained ERM model (should try highly regularized or not) \n",
    "- Then extract the features of the training examples (save into a file somewhere?) \n",
    "- Then perform k-means on the feature space of each label x correctlyclassified to obtain pseudo-group-labels \n",
    "- Then perform some algorithm that can take into account the group information for lowering robust loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd2ee704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b46d5002745d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m optimizer = torch.optim.SGD(\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m             \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "from data.celebA_dataset import CelebADataset\n",
    "from models import model_attributes\n",
    "from data.dro_dataset import DRODataset\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# device='cpu'\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))\n",
    "\n",
    "root_dir = '/home/thiennguyen/research/datasets/celebA/'  # dir that contains data\n",
    "target_name= 'Blond_Hair'  # we are classifying whether the input image is blond or not\n",
    "confounder_names= ['Male']  # we aim to avoid learning spurious features... here it's the gender\n",
    "model_type= 'resnet10vw'  # what model we are using to process --> this is to determine the input size to rescale the image\n",
    "augment_data= False\n",
    "fraction=1.0\n",
    "splits = ['train', 'val', 'test']\n",
    "full_dataset = CelebADataset(root_dir=root_dir,\n",
    "        target_name=target_name,\n",
    "        confounder_names=confounder_names,\n",
    "        model_type=model_type,  # this string is to get the model's input size (for resizing) and input type (image or precomputed)\n",
    "        augment_data=augment_data)  # augment data adds random resized crop and random flip.\n",
    "\n",
    "subsets = full_dataset.get_splits(       # basically return the Subsets object with the appropriate indices for train/val/test\n",
    "        splits,                          # also implements subsampling --> just remove random indices of the appropriate groups in train\n",
    "        train_frac=fraction,   # fraction means how much of the train data to use --> randomly remove if less than 1\n",
    "        subsample_to_minority=False)\n",
    "\n",
    "dro_subsets = [  \n",
    "    DRODataset(\n",
    "        subsets[split],  # process each subset separately --> applying the transform parameter.\n",
    "        process_item_fn=None,\n",
    "        n_groups=full_dataset.n_groups,\n",
    "        n_classes=full_dataset.n_classes,\n",
    "        group_str_fn=full_dataset.group_str) \\\n",
    "    for split in splits]\n",
    "\n",
    "train_data, val_data, test_data = dro_subsets\n",
    "train_loader = train_data.get_loader(train=True, reweight_groups=False, batch_size=128)\n",
    "val_loader = val_data.get_loader(train=False, reweight_groups=None, batch_size=5)\n",
    "test_loader = test_data.get_loader(train=False, reweight_groups=None, batch_size=128)\n",
    "example_batch = next(iter(train_loader))\n",
    "example_batch = tuple(t.to(device) for t in example_batch)\n",
    "x, y, g, idxs = example_batch\n",
    "\n",
    "######################################################\n",
    "###########        Load models and optimizers.  ######\n",
    "######################################################\n",
    "from variable_width_resnet import resnet10vw\n",
    "\n",
    "n_classes = train_data.n_classes\n",
    "n_groups = train_data.n_groups\n",
    "margin_shape = n_classes\n",
    "\n",
    "resnet_width = 16\n",
    "lr = 0.001\n",
    "weight_decay = 0.001\n",
    "# load saved model\n",
    "log_path = 'logs/cluster_w16s0/'\n",
    "log_sr_path = 'logs/cluster_w16s0wd0.1/'\n",
    "model_sr_path = log_sr_path + 'joint/model_100.pth'\n",
    "model_path = log_path + 'joint/model_100.pth'\n",
    "\n",
    "modeln = resnet10vw(resnet_width, num_classes=margin_shape)\n",
    "modeln.load_state_dict(torch.load(model_path))\n",
    "modeln.to(device)\n",
    "\n",
    "model_sr = resnet10vw(resnet_width, num_classes=margin_shape)\n",
    "model_sr.load_state_dict(torch.load(model_sr_path))\n",
    "model_sr.to(device)\n",
    "\n",
    "\n",
    "def freeze_all_but_last_layer(model):\n",
    "    # freeze everything except the last layer\n",
    "    for name, param in model.named_parameters():\n",
    "        if name not in ['fc.weight', 'fc.bias']:\n",
    "            param.requires_grad = False\n",
    "    # make sure that really worked\n",
    "    parameters = list(filter(lambda p: p.requires_grad, model.parameters()))\n",
    "    assert len(parameters) == 2  # fc.weight, fc.bias\n",
    "\n",
    "\n",
    "# initialize the criterion and optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.SGD(\n",
    "            filter(lambda p: p.requires_grad, model.parameters()),\n",
    "            lr=lr,\n",
    "            momentum=0.9,\n",
    "            weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36480ce5",
   "metadata": {},
   "source": [
    "## Train ERM Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0528ba",
   "metadata": {},
   "source": [
    "## Evaluate ERM Model and Obtain Error Set\n",
    "- Load the model \n",
    "- Run it on the training data and partition it into 4 different sets for clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a04e91c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2db184f9dfaa418f8adf99f0ee971123",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1272), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct = tensor(145254, device='cuda:0')\n",
      "correct0 =  tensor(138270, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import itertools  # for cartesian product for loops\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "\n",
    "# while looping through the batch, save a dictionary (where the position of the list match up):\n",
    "# {\n",
    "#     activations : [],  # the features\n",
    "#     labels : [],       # the corresponding labels \n",
    "#     correctly_classified : [], # whether the given model correctly classified\n",
    "#     groups : [], # is this cheating? \n",
    "# }\n",
    "\n",
    "\n",
    "def get_save_features_hook_fn(list_for_features: [torch.Tensor]):\n",
    "    \"\"\"\n",
    "        Returns:\n",
    "            function for forward hook that appends the input (i.e. features) of the last layer to list_for_features\n",
    "    \"\"\"\n",
    "    def hook_fn(self, inp, outp):\n",
    "        list_for_features.append(inp[0].detach().cpu())  # this saves the feature to the given feature list\n",
    "    return hook_fn\n",
    "    \n",
    "def get_output_sets(loader, model, classifying_groups = False):\n",
    "    output_sets = {'activations' : [],  # the features\n",
    "                   'predicted' : [], # the model's prediction\n",
    "#                    'groups' : [], # is this cheating? \n",
    "                   'labels' : [],       # the corresponding labels \n",
    "                   'idx' : []\n",
    "                 }\n",
    "    model.eval()\n",
    "    # the line below makes it so that whenever model.forward is called, we save the features to our activations list.\n",
    "    # the feature handler ensures we remove the hook after we are done extracting the features\n",
    "    feature_handler = model.fc.register_forward_hook(get_save_features_hook_fn(output_sets['activations']))\n",
    "\n",
    "    with torch.set_grad_enabled(False):\n",
    "        for batch_idx, batch in enumerate(tqdm(loader)):\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            x, y, g, idx = batch\n",
    "            outputs = model(x)  \n",
    "            to_predict = g if classifying_groups else y\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            output_sets['labels'].append(y.detach().cpu())\n",
    "            output_sets['predicted'].append(predicted.detach().cpu())\n",
    "            output_sets['idx'].append(idx.detach().cpu())\n",
    "    \n",
    "    feature_handler.remove()  # we unregister the forward hook. \n",
    "    return output_sets\n",
    "\n",
    "output_sets = get_output_sets(train_loader, model_sr)\n",
    "\n",
    "# save output_sets\n",
    "output_dict_save_path = os.path.join(log_sr_path,  'output_sets.pth')\n",
    "torch.save(output_sets, output_dict_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f213a8",
   "metadata": {},
   "source": [
    "## Cluster the sets\n",
    "- First we load the output sets again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f568de26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1272 torch.Size([128, 128])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "group_features_dict = {}  # this contains the features of the different labels/correctly-classified groups\n",
    "group_idx_dict = {}\n",
    "output_sets = torch.load(output_dict_save_path)\n",
    "\n",
    "print(len(output_sets['activations']), output_sets['activations'][0].shape)\n",
    "x_feature = torch.cat(output_sets['activations'])\n",
    "y_array = torch.cat(output_sets['labels'])\n",
    "predicted = torch.cat(output_sets['predicted'])\n",
    "idxs = torch.cat(output_sets['idx'])\n",
    "\n",
    "for label in range(n_classes):\n",
    "    correct_select = (y_array == label) & (y_array == predicted)\n",
    "    group_features_dict[f'class{label}_correct'] = x_feature[correct_select]\n",
    "    group_idx_dict[f'class{label}_correct'] = idxs[correct_select]\n",
    "    \n",
    "    wrong_select = (y_array == label) & (y_array != predicted)\n",
    "    group_features_dict[f'class{label}_wrong'] = x_feature[wrong_select]\n",
    "    group_idx_dict[f'class{label}_wrong'] = idxs[wrong_select]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0051ff73",
   "metadata": {},
   "source": [
    "### Now we can cluster each subgroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e73810cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781.2484003058303\n"
     ]
    }
   ],
   "source": [
    "from copy import copy\n",
    "n_clusters = 4  # 4, 300: 781, \n",
    "max_iter = 300  # 5, 300: 535.927, 400: \n",
    "\n",
    "cluster_assignments = {}\n",
    "\n",
    "for label in range(n_classes):\n",
    "    for stat in ['correct', 'wrong']:\n",
    "        cluster_model = KMeans(n_clusters, max_iter=max_iter)\n",
    "        cluster_model.fit(group_features_dict[f'class{label}_{stat}'])\n",
    "        cluster_assignments[f'class{label}_{stat}'] = copy(cluster_model.labels_)\n",
    "\n",
    "    \n",
    "print(cluster_model.inertia_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759c61b3",
   "metadata": {},
   "source": [
    "## Finally retrain with gDRO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "515fb131",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([1,2,3])\n",
    "b = torch.tensor([4,5,6])\n",
    "torch.stack([a,b])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4f00f7",
   "metadata": {},
   "source": [
    "# PLAYGROUND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7225dff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([138270, 128])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_feature[(y_array == 0) & (y_array == predicted)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "781faafa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
      "        0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
      "        0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
      "        1, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([116512,  86576, 137033, 137783,  41092, 124173,  55239,  72699,  91503,\n",
      "         39249, 140607,  33405,  35304,  98070,  89792,  30422,  42185, 127753,\n",
      "        133399,  49669,  10597,   1907,  23412, 122663, 132795,  11350,  49146,\n",
      "        136059,  92930,  17800, 143768,  43261, 100543,  16203,  18786,  53670,\n",
      "         73070,  79761, 117203, 119135,  90050,  85270, 117438, 161047, 146605,\n",
      "        158457,  53547, 154838,  26025,  21408,  24719,  12405,  11870,  68837,\n",
      "          3229, 136679,  47042,  74359,  86986, 102683, 105254,  91918, 124831,\n",
      "        143581,  32862,  67845,  90193,  23095,  80341,   4068,  44223, 113745,\n",
      "         17024,  99588,  53284,  18192,  82366,  78202,  74944,  48619, 105401,\n",
      "         45699,  86736, 162564, 127440, 129152,  90281, 121655, 137138, 105555,\n",
      "        144738,   1960, 105210, 102164,  29702, 160608, 116402,  48100, 112067,\n",
      "          1149, 132157,  81982, 130300,  18743,  73463,  61076,  15688, 124098,\n",
      "         36976,  70666,  53980,  46209,  15880, 155393, 152950,  68808,  98545,\n",
      "         83046, 162318, 121945,  63439, 151894, 139379, 149241, 133724, 107680,\n",
      "        122864, 126772])\n"
     ]
    }
   ],
   "source": [
    "# print(y_array[0:30])\n",
    "print(output_sets['labels'][0])\n",
    "print(output_sets['idx'][0])\n",
    "\n",
    "\n",
    "# tensor([0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
    "#         0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "#         0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
    "#         0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
    "#         0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
    "#         1, 0, 0, 0, 0, 0, 0, 0])\n",
    "# tensor([116512,  86576, 137033, 137783,  41092, 124173,  55239,  72699,  91503,\n",
    "#          39249, 140607,  33405,  35304,  98070,  89792,  30422,  42185, 127753,\n",
    "#         133399,  49669,  10597,   1907,  23412, 122663, 132795,  11350,  49146,\n",
    "#         136059,  92930,  17800, 143768,  43261, 100543,  16203,  18786,  53670,\n",
    "#          73070,  79761, 117203, 119135,  90050,  85270, 117438, 161047, 146605,\n",
    "#         158457,  53547, 154838,  26025,  21408,  24719,  12405,  11870,  68837,\n",
    "#           3229, 136679,  47042,  74359,  86986, 102683, 105254,  91918, 124831,\n",
    "#         143581,  32862,  67845,  90193,  23095,  80341,   4068,  44223, 113745,\n",
    "#          17024,  99588,  53284,  18192,  82366,  78202,  74944,  48619, 105401,\n",
    "#          45699,  86736, 162564, 127440, 129152,  90281, 121655, 137138, 105555,\n",
    "#         144738,   1960, 105210, 102164,  29702, 160608, 116402,  48100, 112067,\n",
    "#           1149, 132157,  81982, 130300,  18743,  73463,  61076,  15688, 124098,\n",
    "#          36976,  70666,  53980,  46209,  15880, 155393, 152950,  68808,  98545,\n",
    "#          83046, 162318, 121945,  63439, 151894, 139379, 149241, 133724, 107680,\n",
    "#         122864, 126772])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77cb34b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "556b7ddb692844e7bb1f474eda7f9b5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1272), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking whether the number between saving and loading lists above is the same as brute force\n",
    "\n",
    "import itertools\n",
    "\n",
    "model.eval()\n",
    "\n",
    "test_dict = {f'class{label}_{stat}':[] for label,stat in itertools.product(range(n_classes), ['correct', 'wrong'])}\n",
    "\n",
    "with torch.set_grad_enabled(False):\n",
    "    for batch_idx, batch in enumerate(tqdm(loader)):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        x, y, g, idx = batch\n",
    "        outputs = model(x)  \n",
    "        to_predict = y\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        for label in range(n_classes):\n",
    "            test_dict[f'class{label}_correct'] += [x[(to_predict == predicted) & (y == label)].cpu().numpy()]\n",
    "            test_dict[f'class{label}_wrong'] += [x[(to_predict != predicted) & (y == label)].cpu().numpy()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1628bf11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class0_correct (138503, 3, 224, 224)\n",
      "class0_wrong (0, 3, 224, 224)\n",
      "class1_correct (23646, 3, 224, 224)\n",
      "class1_wrong (621, 3, 224, 224)\n"
     ]
    }
   ],
   "source": [
    "for key in test_dict:\n",
    "    print(key, np.concatenate(test_dict[key], axis=0).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cc9698e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      " [[0.19225536 0.72425263 0.78405661]\n",
      " [0.69527028 0.74528752 0.11246908]\n",
      " [0.44786416 0.15620919 0.70220325]\n",
      " [0.47935582 0.34016257 0.35106018]\n",
      " [0.55154411 0.66761181 0.01698646]]\n",
      "[[0.21949124 0.86183075 0.90310517]\n",
      " [0.94968505 0.3059399  0.84207108]\n",
      " [0.01026236 0.90690631 0.04055816]\n",
      " [0.31990618 0.9845833  0.43567266]\n",
      " [0.14328209 0.80166115 0.72445191]]\n",
      "[0 1 0 1 0]\n",
      "[0 0 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "a = np.random.rand(5,3)\n",
    "b = np.random.rand(5,3)\n",
    "c = np.array([0,1,0,1,0])\n",
    "d = np.array([0,0,1,1,0])\n",
    "print('a\\n',a)\n",
    "# print(b)\n",
    "print(c)\n",
    "print(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "81b75ba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.19225536, 0.72425263, 0.78405661],\n",
       "       [0.55154411, 0.66761181, 0.01698646]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d==True\n",
    "a[(c==0) & (d==False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3158a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "output_sets = {'activations' : [],  # the features\n",
    "               'predicted' : [], # the model's prediction\n",
    "               'labels' : [],       # the corresponding labels \n",
    "               'idx' : []\n",
    "             }\n",
    "# the line below makes it so that whenever model.forward is called, we save the features to our activations list.\n",
    "# the feature handler ensures we remove the hook after we are done extracting the features\n",
    "feature_handler = model.fc.register_forward_hook(get_save_features_hook_fn(output_sets['activations']))\n",
    "stop = 0\n",
    "with torch.set_grad_enabled(False):\n",
    "    for batch_idx, batch in enumerate(tqdm(train_loader)):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        x, y, g, idx = batch\n",
    "\n",
    "        outputs = model(x)  \n",
    "        to_predict =  y\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        output_sets['labels'].append(y.cpu())\n",
    "        output_sets['predicted'].append(predicted.cpu())\n",
    "        output_sets['idx'].append(idx.cpu())\n",
    "        print('x', x.norm())\n",
    "        print('pred', predicted)\n",
    "        print('y',y)\n",
    "        print('idx', idx)\n",
    "        print('----')\n",
    "        break\n",
    "        \n",
    "    \n",
    "\n",
    "# print()\n",
    "# for k in output_sets:\n",
    "#     if k == 'activations':\n",
    "#         print(k, [output_sets[k][j].norm() for j in range(len(output_sets[k]))])\n",
    "#     else:\n",
    "#         print(k, output_sets[k])\n",
    "#         print(torch.cat(output_sets[k]))\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "686px",
    "left": "883px",
    "right": "20px",
    "top": "167px",
    "width": "445px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
